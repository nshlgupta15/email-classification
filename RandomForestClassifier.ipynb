{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email Classification Using Random Forest Classifier \n",
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the input dataset and dividing the input dataset int features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the input dataset\n",
    "dataset = pd.read_csv(\"/Users/anshulgupta/Desktop/spambase/spambase_data.csv\")\n",
    "\n",
    "# dividing the input dataset int features and label\n",
    "features = dataset.iloc[:, 0:57].values\n",
    "label = dataset.iloc[:, 57].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using k fold with 5 folds and dividing the dataset into train and test set.\n",
    "on every iteration of kfold, new set of 920 data sets are taken as test set and remaining as training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Evaluation 1:\n",
      "tn, fp, fn, tp: [  0   0 133 788]\n",
      "Accuracy: 0.8555917480998915\n",
      "Mean Error: 0.1444082519001086\n",
      "\n",
      "\n",
      "Fold Evaluation 2:\n",
      "tn, fp, fn, tp: [ 28   0 123 769]\n",
      "Accuracy: 0.866304347826087\n",
      "Mean Error: 0.13369565217391305\n",
      "\n",
      "\n",
      "Fold Evaluation 3:\n",
      "tn, fp, fn, tp: [892  28   0   0]\n",
      "Accuracy: 0.9695652173913043\n",
      "Mean Error: 0.030434782608695653\n",
      "\n",
      "\n",
      "Fold Evaluation 4:\n",
      "tn, fp, fn, tp: [885  35   0   0]\n",
      "Accuracy: 0.9619565217391305\n",
      "Mean Error: 0.03804347826086957\n",
      "\n",
      "\n",
      "Fold Evaluation 5:\n",
      "tn, fp, fn, tp: [737 183   0   0]\n",
      "Accuracy: 0.8010869565217391\n",
      "Mean Error: 0.19891304347826086\n",
      "\n",
      "\n",
      "overall misclassified 502\n",
      "total data set 4601\n",
      "average error 0.10910671593131928\n"
     ]
    }
   ],
   "source": [
    "# using k fold with 5 folds\n",
    "kf = KFold(n_splits=5, random_state=None)\n",
    "misclassified = 0\n",
    "total = 0 \n",
    "count = 1\n",
    "\n",
    "for train_index, test_index in kf.split(features):\n",
    "    \n",
    "  # dividing the dataset int train and test set\n",
    "  # on every iteration of kfold, new set of 920 emails are taken as test set and remaining as training set\n",
    "  features_train, features_test = features[train_index], features[test_index]\n",
    "  label_train, label_test = label[train_index], label[test_index]\n",
    "\n",
    "  # Feature Scaling\n",
    "  sc = StandardScaler()\n",
    "  features_train = sc.fit_transform(features_train)\n",
    "  features_test = sc.transform(features_test)\n",
    "\n",
    "  # training the algorithm\n",
    "  classifier = RandomForestClassifier(n_estimators=40, random_state=0)\n",
    "  classifier.fit(features_train, label_train)\n",
    "  label_pred = classifier.predict(features_test)\n",
    "\n",
    "  # evaluating the algorithm\n",
    "  print('Fold Evaluation', str(count) + ':')\n",
    "  # (tn, fp, fn, tp)\n",
    "  result = confusion_matrix(label_test, label_pred).ravel()\n",
    "  print('tn, fp, fn, tp:', result)\n",
    "  misclassified = misclassified + result[1] + result[2]\n",
    "  total = total + result[0] + result[1] + result[2] + result[3]\n",
    "  # print(classification_report(label_test, label_pred))\n",
    "  print('Accuracy:', accuracy_score(label_test, label_pred))\n",
    "  print('Mean Error:', metrics.mean_absolute_error(label_test, label_pred))  \n",
    "  print('\\n')\n",
    "  count = count + 1  \n",
    "\n",
    "print ('overall misclassified', misclassified)\n",
    "print ('total data set', total)\n",
    "print ('average error', (misclassified/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
